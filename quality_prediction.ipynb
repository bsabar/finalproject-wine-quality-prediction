{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c10eb319-fa1f-48d1-bc86-d18d3721083a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4              0.70         0.00             1.9      0.076   \n",
       "1               7.8              0.88         0.00             2.6      0.098   \n",
       "2               7.8              0.76         0.04             2.3      0.092   \n",
       "3              11.2              0.28         0.56             1.9      0.075   \n",
       "4               7.4              0.70         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "6492            6.2              0.21         0.29             1.6      0.039   \n",
       "6493            6.6              0.32         0.36             8.0      0.047   \n",
       "6494            6.5              0.24         0.19             1.2      0.041   \n",
       "6495            5.5              0.29         0.30             1.1      0.022   \n",
       "6496            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "6492                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "6493                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "6494                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "6495                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "6496                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  color  \n",
       "0         9.4        5    red  \n",
       "1         9.8        5    red  \n",
       "2         9.8        5    red  \n",
       "3         9.8        6    red  \n",
       "4         9.4        5    red  \n",
       "...       ...      ...    ...  \n",
       "6492     11.2        6  white  \n",
       "6493      9.6        5  white  \n",
       "6494      9.4        6  white  \n",
       "6495     12.8        7  white  \n",
       "6496     11.8        6  white  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  # Import imputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('quality.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962d8cda-e23c-4fa6-896d-c7d03340cc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.215307</td>\n",
       "      <td>0.339666</td>\n",
       "      <td>0.318633</td>\n",
       "      <td>5.443235</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>30.525319</td>\n",
       "      <td>115.744574</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>3.218501</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>10.491801</td>\n",
       "      <td>5.818378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.296434</td>\n",
       "      <td>0.164636</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>4.757804</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>17.749400</td>\n",
       "      <td>56.521855</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>1.192712</td>\n",
       "      <td>0.873255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    6497.000000       6497.000000  6497.000000     6497.000000   \n",
       "mean        7.215307          0.339666     0.318633        5.443235   \n",
       "std         1.296434          0.164636     0.145318        4.757804   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.400000          0.230000     0.250000        1.800000   \n",
       "50%         7.000000          0.290000     0.310000        3.000000   \n",
       "75%         7.700000          0.400000     0.390000        8.100000   \n",
       "max        15.900000          1.580000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  6497.000000          6497.000000           6497.000000  6497.000000   \n",
       "mean      0.056034            30.525319            115.744574     0.994697   \n",
       "std       0.035034            17.749400             56.521855     0.002999   \n",
       "min       0.009000             1.000000              6.000000     0.987110   \n",
       "25%       0.038000            17.000000             77.000000     0.992340   \n",
       "50%       0.047000            29.000000            118.000000     0.994890   \n",
       "75%       0.065000            41.000000            156.000000     0.996990   \n",
       "max       0.611000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000  \n",
       "mean      3.218501     0.531268    10.491801     5.818378  \n",
       "std       0.160787     0.148806     1.192712     0.873255  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.110000     0.430000     9.500000     5.000000  \n",
       "50%       3.210000     0.510000    10.300000     6.000000  \n",
       "75%       3.320000     0.600000    11.300000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     9.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f1a5cb-94b9-497a-8e1e-ba31c44faea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0.0\n",
       "volatile acidity        0.0\n",
       "citric acid             0.0\n",
       "residual sugar          0.0\n",
       "chlorides               0.0\n",
       "free sulfur dioxide     0.0\n",
       "total sulfur dioxide    0.0\n",
       "density                 0.0\n",
       "pH                      0.0\n",
       "sulphates               0.0\n",
       "alcohol                 0.0\n",
       "quality                 0.0\n",
       "color                   0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e19a7d8b-d9e5-4c8c-9bd6-e637fc3a4376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 4, 8, 3, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['quality'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9463bee-2232-42e9-b7b9-adf7a0cbc02a",
   "metadata": {},
   "source": [
    "## Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9a61761-2e91-4a1b-abcd-1ef38863f458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.17      0.29         6\n",
      "           4       1.00      0.07      0.13        43\n",
      "           5       0.54      0.61      0.57       402\n",
      "           6       0.54      0.68      0.61       597\n",
      "           7       0.53      0.23      0.32       215\n",
      "           8       1.00      0.00      0.00        36\n",
      "           9       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.54      1300\n",
      "   macro avg       0.80      0.25      0.27      1300\n",
      "weighted avg       0.57      0.54      0.51      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert color labels to numerical values using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data['color'] = le.fit_transform(data['color'])\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the scaled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Logistic Regression model with increased max_iter\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Generate and print the classification report with zero_division parameter\n",
    "class_report = classification_report(y_test, y_pred, zero_division=1)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c50e1-0912-4b97-97f8-d0e360230ea3",
   "metadata": {},
   "source": [
    "## naives baye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e56301e-5125-4690-8df3-993ff8a2f690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.06      0.17      0.09         6\n",
      "           4       0.11      0.14      0.12        43\n",
      "           5       0.51      0.60      0.55       402\n",
      "           6       0.56      0.40      0.47       597\n",
      "           7       0.37      0.55      0.44       215\n",
      "           8       0.40      0.06      0.10        36\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.47      1300\n",
      "   macro avg       0.29      0.27      0.25      1300\n",
      "weighted avg       0.49      0.47      0.47      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "datanb = pd.read_csv('quality.csv')  # Make sure to replace with the actual path to your dataset\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop(['quality', 'color'], axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Generate a classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=sorted(y.unique()), yticklabels=sorted(y.unique()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd0292-f8c3-4d87-acfc-98e4cc1d84e5",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "660d2d34-8504-4bc8-ae11-858c59b0b213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5453846153846154\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.33      0.17      0.22         6\n",
      "           4       0.25      0.14      0.18        43\n",
      "           5       0.54      0.64      0.59       402\n",
      "           6       0.58      0.60      0.59       597\n",
      "           7       0.51      0.40      0.45       215\n",
      "           8       0.21      0.08      0.12        36\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.55      1300\n",
      "   macro avg       0.35      0.29      0.31      1300\n",
      "weighted avg       0.53      0.55      0.54      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data_knn = pd.read_csv('quality.csv')\n",
    "\n",
    "# Convert color column to numerical values (0 for red, 1 for white)\n",
    "color_encoder = LabelEncoder()\n",
    "data_knn['color'] = color_encoder.fit_transform(data_knn['color'])\n",
    "\n",
    "# Separate features and target\n",
    "X = data_knn.drop('quality', axis=1)\n",
    "y = data_knn['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "k = 5  # Number of neighbors\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Train the KNN classifier\n",
    "knn_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23b82612-953a-46e6-889b-02a8f8983189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('wine_complete.csv')  # Replace 'wine_data.csv' with the actual path to your dataset\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(['quality', 'color'], axis=1)\n",
    "y = data['quality']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fde551b5-cb0d-40df-bb36-ca525efa1cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4              0.70         0.00             1.9      0.076   \n",
       "1               7.8              0.88         0.00             2.6      0.098   \n",
       "2               7.8              0.76         0.04             2.3      0.092   \n",
       "3              11.2              0.28         0.56             1.9      0.075   \n",
       "4               7.4              0.70         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "6492            6.2              0.21         0.29             1.6      0.039   \n",
       "6493            6.6              0.32         0.36             8.0      0.047   \n",
       "6494            6.5              0.24         0.19             1.2      0.041   \n",
       "6495            5.5              0.29         0.30             1.1      0.022   \n",
       "6496            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "6492                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "6493                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "6494                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "6495                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "6496                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  \n",
       "0         9.4  \n",
       "1         9.8  \n",
       "2         9.8  \n",
       "3         9.8  \n",
       "4         9.4  \n",
       "...       ...  \n",
       "6492     11.2  \n",
       "6493      9.6  \n",
       "6494      9.4  \n",
       "6495     12.8  \n",
       "6496     11.8  \n",
       "\n",
       "[6497 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d606cc5-1ab4-4d61-8a2d-e000e81b90ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.06      0.17      0.09         6\n",
      "           4       0.11      0.14      0.12        43\n",
      "           5       0.51      0.60      0.55       402\n",
      "           6       0.56      0.40      0.47       597\n",
      "           7       0.37      0.55      0.44       215\n",
      "           8       0.40      0.06      0.10        36\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.47      1300\n",
      "   macro avg       0.29      0.27      0.25      1300\n",
      "weighted avg       0.49      0.47      0.47      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = naive_bayes.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08e9f90-14a0-4622-a3c4-98cc8924363e",
   "metadata": {},
   "source": [
    "## svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbc0de13-1421-44c0-969a-ad0093949f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00        43\n",
      "           5       0.38      0.16      0.23       402\n",
      "           6       0.46      0.87      0.60       597\n",
      "           7       0.00      0.00      0.00       215\n",
      "           8       0.00      0.00      0.00        36\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.45      1300\n",
      "   macro avg       0.12      0.15      0.12      1300\n",
      "weighted avg       0.33      0.45      0.35      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load the dataset\n",
    "data_svc = pd.read_csv('wine_complete.csv')  # Replace 'wine_data.csv' with your actual file name\n",
    "\n",
    "# Split the data into features (X) and target labels (y)\n",
    "X = data.drop(['quality', 'color'], axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SVC model\n",
    "modelsvc = SVC()\n",
    "\n",
    "# Train the model\n",
    "modelsvc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the wine quality\n",
    "y_pred = modelsvc.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339788b8-0fde-4d9c-b10c-58e4a488fedb",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0a94a1b-3905-45c9-b096-6cf20c97ef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.71      0.12      0.20        43\n",
      "           5       0.67      0.71      0.69       402\n",
      "           6       0.66      0.75      0.70       597\n",
      "           7       0.71      0.55      0.62       215\n",
      "           8       0.92      0.33      0.49        36\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67      1300\n",
      "   macro avg       0.52      0.35      0.39      1300\n",
      "weighted avg       0.67      0.67      0.66      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('wine_complete.csv')  # Replace 'wine_complete.csv' with your actual file name\n",
    "\n",
    "# Split the data into features (X) and target labels (y)\n",
    "X = data.drop(['quality', 'color'], axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestClassifier model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the wine quality\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3932af7-3641-483d-aac7-42ed16f3fa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Accuracy: 0.68\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.71      0.12      0.20        43\n",
      "           5       0.68      0.72      0.70       402\n",
      "           6       0.67      0.77      0.71       597\n",
      "           7       0.72      0.57      0.64       215\n",
      "           8       0.92      0.33      0.49        36\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.68      1300\n",
      "   macro avg       0.53      0.36      0.39      1300\n",
      "weighted avg       0.69      0.68      0.67      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('wine_complete.csv')  # Replace 'wine_complete.csv' with your actual file name\n",
    "\n",
    "# Split the data into features (X) and target labels (y)\n",
    "X = data.drop(['quality', 'color'], axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict the wine quality\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32fd4f0e-1939-4151-9e74-70994c00103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Accuracy: 0.66\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.25      0.17      0.20         6\n",
      "           4       0.35      0.40      0.37        43\n",
      "           5       0.68      0.75      0.71       402\n",
      "           6       0.71      0.64      0.67       597\n",
      "           7       0.59      0.62      0.61       215\n",
      "           8       0.53      0.50      0.51        36\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.66      1300\n",
      "   macro avg       0.44      0.44      0.44      1300\n",
      "weighted avg       0.66      0.66      0.66      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/micahgalbadores/anaconda3/envs/pythondataucb/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  10.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   9.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=  11.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=  13.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=  11.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   8.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   8.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  10.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   9.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=  11.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   8.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   9.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  11.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   8.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   9.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   9.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=  11.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   8.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   8.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   8.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=  11.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=  13.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  12.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=  11.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   9.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   9.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   9.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=  11.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=  13.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  12.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   9.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=  12.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=  11.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   8.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   8.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   9.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  11.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=  12.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=  11.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  11.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=  10.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=  12.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=  12.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=  12.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=  12.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  11.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=  11.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=  12.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   6.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   8.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   9.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   9.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=  11.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=  12.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=  11.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   7.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   8.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   8.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   8.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   8.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=  11.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   8.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   8.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  12.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   8.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   9.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   9.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  12.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   8.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   9.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  12.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   6.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=  12.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=  11.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  12.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=  13.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   8.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   8.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   7.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   8.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   8.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   9.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   8.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   9.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   9.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=  12.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=  12.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=  11.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   9.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   9.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  10.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=  12.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   8.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   8.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   8.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=  12.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   8.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   8.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   8.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  10.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   7.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   9.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   8.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   9.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=  12.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  12.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=  10.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   9.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  13.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=  12.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   8.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   9.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   9.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=  11.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   9.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   9.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   9.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   5.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=  11.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=  11.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  10.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   9.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  10.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   9.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   9.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=  12.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   9.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   9.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   9.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=  11.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=  12.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=  12.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=  11.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=  12.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  11.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=  12.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=  11.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=  11.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   8.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   8.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   8.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   8.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=  13.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  11.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=  12.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=  13.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   8.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   9.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   8.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   9.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   9.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=  12.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   8.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   8.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   8.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  12.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=  11.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=  12.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=  11.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   8.5s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('wine_complete.csv')  # Replace 'wine_complete.csv' with your actual file name\n",
    "\n",
    "# Split the data into features (X) and target labels (y)\n",
    "X = data.drop(['quality', 'color'], axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply StandardScaler to scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Inspect class distribution\n",
    "class_counts = y_train.value_counts()\n",
    "\n",
    "# Find the minimum class count\n",
    "min_class_count = class_counts.min()\n",
    "\n",
    "# Reduce k_neighbors to a value smaller than min_class_count\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=min_class_count-1, random_state=42)\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_depth': [20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier model\n",
    "model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Initialize GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Perform GridSearchCV on the resampled data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict the wine quality\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94eaac54-f2fc-4893-95bc-ddcf7b365193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('wine_complete.csv')  # Replace 'wine_data.csv' with your actual data file name\n",
    "\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = data.drop(['quality', 'color'], axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ec0d7-d633-4c84-8806-759fb45756b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pythondataucb)",
   "language": "python",
   "name": "pythondataucb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
